---
title: "Fermentation"
date: "`r format(Sys.Date())`"
author:
- Douglas Campbell^1^*
- Carlie Barnhill^1^*
- Jacob MacPhee^1^*

output:
  bookdown::html_document2:
    code_folding: show
    keep_md: yes
    toc: TRUE
    toc_float: TRUE
    toc_depth: 6
    fig_caption: yes
bibliography: RPackageCitations.bib
csl: plos-one.csl
editor_options: 
  markdown: 
    wrap: 72
---
```{css, echo=FALSE}
p.caption {
  font-size: 18px;
}
```


# Affiliations {-}
^1^Mount Allison University, New Brunswick, Canada  

*corresponding author  

# Acknowledgements {-}
Brackets minus after heading excludes heading from numbering.
DAC was supported by the Canada Research Chairs.

# Overview
File import functions read files into R objects, commonly data frames. 

# Materials & Methods  
## Set chunk options
Formatted display of content from .md file on GitHub site.
Upon knitr figures will be saved to 'Figs/'
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, error = FALSE, message = FALSE)
knitr::opts_chunk$set(fig.path='Figs/')
```

## Load packages
```{r packages, include = FALSE}
library(tidyverse) #core packages from Tidyverse
library(googledrive) #access to GoogleDrive
library(googlesheets4) #access to GoogleSheets
library(data.table) #fast data handling;  complement to tidverse dplyr
library(lubridate) #tidyverse handling dates & times
```

## InLine Citations of software packages added through the 'citr' option under 'Addins'.  
The cited items must be in the .bib file saved in the .Rproj folder; in this case RPackageCitations.bib, generated by exporting a library to .bib from Zotero.  Upon export click the 'Keep Updated' button in the BetterBibTex menu.  If new citations are added to Zotero they will be pushed through to update the exported .bib file in the .Rproj folder.
[@bryanGooglesheets4AccessGoogle2021;@mcgowanGoogledriveInterfaceGoogle2020; @wickhamTidyverseEasilyInstall2017]

## Source locally saved functions stored in a text file
A text file of functions is a preliminary step towards a package, to re-use functions without repasting them.

```{r source CampbellLabRFunctions.txt}
source("FundyPhytoFunctions.txt")
```
```{r show equations}
#linear equations are in base R but a user defined equation may be convenient for use in parallel with other user defined equations
linear_eqn
exp_eqn
gompertz_eqn
logistic_eqn

read_plus_csv
data_with_sources_csv

```


## Set Project Variables  
Try to set all user-defined variables near top of .Rmd, in one place, to avoid or limit editing of downstream code.
Assigning project-specific values to generic variables helps with re-use of code.
```{r set variables}
DataIn <- "XXXX"
TargetFile <- "YYYY"
  
```


# Import MetaData from a GoogleSheet
MetaData in a GoogleSheet is more generic than a project-specific .csv edited and saved locally.
The GoogleSheet interface can be tricky.
Repeatedly reading from GoogleDrive can provoke a throttle from Google.
```{r load Catalog direct from googlesheet, results = "hide"}

#Instead of sending a token, googlesheets4 will send an API key. This can be used to access public resources for which no Google sign-in is required. 
googlesheets4::gs4_deauth()

#URL or ID of a GoogleSheet readable by anyone (with a link)
Catalog <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1ZXpwR7Gfto-uRzVdXzMpQF4frbrvMLH_IyLqonFZRSw/edit#gid=0") %>%
  # googlesheets4::read_sheet has a  "feature" to set the type of columns it can't parse to a list.
  # ggplot/dplyr does not like working with a dataframe of lists.
  # In this case variable column WL is set to a list since some values are numbers, some are strings, some are blank.
  # To fix this, first drop all rows missing WL, then unlist.
  # Must first drop NA rows since unlist will collapse NULL lists, then the unlisted WL is a shorter length than original WL column, which mutate does not like.
  drop_na(WL) %>%
  mutate(WL = unlist(WL))


Catalog <- as.data.frame(Catalog) %>%
  mutate(ExpDate = lubridate::ymd(ExpDate))
```

```{r}
# Install the googlesheets4 package if not already installed
install.packages("googlesheets4")

# Load the googlesheets4 library
library(googlesheets4)
```
```{r Retrieve ATMetaData}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/17dDzASxhWDbVpQFXb201vT2oB0rkyi2h4gG33ArOaDA/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
ATMetaData <- read_sheet(sheet_url)

# View the imported data (optional)
View(ATMetaData)
```

```{r Retrieve SpecificGravityMetaData}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/15Qd3DYkeRX4FCy84Uw9ns9L6Bq6P959csP-opdGvBME/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
SpecificGravityMetaData <- read_sheet(sheet_url)

# View the imported data (optional)
View(SpecificGravityMetaData)
```

```{r Retrieve BrothPlateMetaData}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/118YF2qZqtC5yCfqyDeRaGQhgm5v8mn6wC_6ae1Rnyik/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
BrothPlateMetaData <- read_sheet(sheet_url)

# View the imported data (optional)
View(BrothPlate1MetaData)
```

```{r Retrieve VitalityFermentationMetaData}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/1mKZNT4blSBhuVf4K8_ddhGqOaep2aScUVqMXixWkkwI/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
VitalityFermentationMetaData <- read_sheet(sheet_url)

# View the imported data (optional)
View(VitalityFermentationMetaData)
```

```{r Retrieve NotesMetaData}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/1phYyUXKip9W4sfQH6zrZxw49RH5AH72zuFHsqgvMoTQ/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
NotesMetaData <- read_sheet(sheet_url)

# View the imported data (optional)
View(NotesMetaData)
```

```{r Retrieve DataDictionary}
# Authenticate with Google Sheets (you only need to do this once)
gs4_auth()

# Define the Google Sheet URL (replace with your actual URL)
sheet_url <- "https://docs.google.com/spreadsheets/d/1YN_s-YRdM4j9t_c_l1Z4-Q53KQlURTlDpItovzZNd3g/edit?usp=sharing"

# Read the Google Sheet into R as a data frame
DataDictionary <- read_sheet(sheet_url)

# View the imported data (optional)
View(DataDictionary)
```

## Function using data.table::fread to skip the beginning comments and start reading file after key word string set as variable Skip.  
Function creates a new variable column Filename whose value will equal function input Flnm.
This is useful for when reading in multiple files and tagging each data row with the name of the source file.
```{r fread_plus}
fread_plus <- function(Flnm, Skip){data.table::fread(file = Flnm, skip = Skip) %>%
    mutate(Filename = Flnm, CDateTime = ymd_hms(file.info(Flnm)$ctime))
}
```

```{r Read single TargetFile}
TargetData <- fread_plus(Flnm = TargetFile, Skip = "key") %>%
select(-c(V5))

TargetData[1:10,]
```

Vector of files for Project that are saved in folder DataIn, containing the pattern Project in their file name
```{r MultiCulti files}
MultiFiles <- list.files(path = DataIn, pattern = Project, full.names = TRUE)

#check file names
MultiFiles

```

Read multiple parallel files contained in DataIn using purrr::map to step through file names in MultiFiles vector
```{r read multiple files}
MultiData <- MultiFiles %>%
  map_df(~fread_plus(Flnm = ., Skip = "key"))
```


\newpage

# Bibliography
